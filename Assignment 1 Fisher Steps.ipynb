{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An overview of our classifier:\n",
        "This classifier is going to be a one versus all fisher linear discriminant. It's going to classify numbers from 0 to 9 which means it will have 10 classes.\n",
        "\n",
        "We are going to make our One_vs_all_fisher class, to instantiate this class we will need to pass our training data and training labels. The first two methods in the class are helper methods to clalculate means and covariances.\n",
        "\n",
        "The first method of interest in this class, which will be called on instantiation, is the train method. This method will take each class individually and calculat the parameters we will need for our classifier method.\n",
        "\n",
        "After the train method is run, class variabe is made. it's a dictionary that has every class from 0 to 9 as keys and for each one it will hold the following values:\n",
        "- The optimal weight vector: w\n",
        "- The bias weight: w0 \n",
        "- The mean of the projected points belonging to the class: y_mean\n",
        "- And their standard deviation: y_std\n",
        "\n",
        "Now once we have made an instance of our classifier, we will be able to use its final method to classify our test data. The classify method takes the training data as its only argument.\n",
        "\n",
        "# The classifier workflow:\n",
        "The work flow is going to include projecting the points by dotting with each class wright vector, calculating the Z-score, used here as the normalized distance between the point and the respective class mean, and then assign the label with the lowest Z-score for each point.\n",
        "\n",
        "After that, we will still have some unclassified point. These are the points that were smaller than w0 for all classes. Since these points will always be \"to the left of\" or \"less than\" w0, we can calculate the normalized distance between them and w0 for each class as a fraction of w0. We assign the label of the smallest distance\n",
        "\n## Below is a flowchart further breaking down the process."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](Workflow.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n\n",
        "class One_vs_all_fisher:\n",
        "  def __init__(self, images, labels):\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "    self.classes = np.unique(lbls)\n",
        "    self.train()\n",
        "\n",
        "# Function to calculate the mean of the intended class and the mean of other classes\n",
        "  def m(self, c1, images_c1, images_c2):\n",
        "      m1= []\n",
        "      for i in range(images_c1.shape[1]):\n",
        "          m1.append(np.sum(images_c1[:,i])/images_c1[:,i].shape[0])\n",
        "\n",
        "      m2=[]\n",
        "      for i in range(images_c2.shape[1]):\n",
        "          m2.append(np.sum(images_c2[:,i])/images_c2[:,i].shape[0])\n",
        "      return np.asarray(m1).reshape(1,-1),  np.asarray(m2).reshape(1,-1)\n",
        "\n",
        "# Function to calculate the covariance of the intended class and the mean of other classes\n",
        "  def S(self, c1, images_c1, images_c2, means):\n",
        "    term1 = images_c1 - means[0]\n",
        "\n",
        "    term2 = images_c2 - means[1]\n",
        "    return (term1.T).dot(term1), (term2.T).dot(term2)\n",
        "\n\n",
        "  def train(self):\n",
        "    # Dictionary that will contain W, W0, projected class values mean and standard deviatiom\n",
        "    self.training_values = {}\n",
        "\n",
        "    for i in self.classes:\n",
        "      images_c1 =self.images[self.labels == i,:]\n",
        "      images_c2 = self.images[self.labels != i,:]\n",
        "      means = self.m(i, images_c1, images_c2)\n",
        "      covariances = self.S(i, images_c1, images_c2, means)\n",
        "\n",
        "      Sw = np.matrix(covariances[0] + covariances[1])\n",
        "      w = np.linalg.pinv(Sw).dot((means[0]-means[1]).T)\n",
        "      w0 = float(.5*(means[0]+means[1]).dot(w))\n",
        "\n",
        "      y_class = np.asarray(np.dot(w.T,images_c1.T)).reshape(-1)\n",
        "      y_mean = sum(y_class)/len(y_class)\n",
        "      y_std = np.std(y_class)\n",
        "\n",
        "      self.training_values[i] = w, w0, y_mean, y_std\n",
        "\n\n\n",
        "  def classify(self, test_images):\n",
        "    labels = np.empty((test_images.shape[0] ,) , dtype = int)\n",
        "    zscores = np.empty((test_images.shape[0] ,) , dtype = int)\n",
        "    y_all = []\n",
        "    for i in self.classes:\n",
        "      w = self.training_values[i][0]\n",
        "      w0 = self.training_values[i][1]\n",
        "      y_mean = self.training_values[i][2]\n",
        "      y_std = self.training_values[i][3]\n",
        "      y = np.asarray(np.dot(w.T,test_images.T)).reshape(-1)\n",
        "      y_all.append(y)\n",
        "      for image_index in range(len(y)):\n",
        "        if labels[image_index] in self.classes:\n",
        "          zscore = np.absolute((y[image_index] - y_mean)/y_std)\n",
        "          if zscores[image_index] > zscore:\n",
        "            labels[image_index] = i\n",
        "            zscores[image_index] = zscore\n",
        "        else:\n",
        "          if y[image_index] > w0:\n",
        "            zscore = np.absolute((y[image_index] - y_mean)/y_std)\n",
        "            labels[image_index] = i\n",
        "            zscores[image_index] = zscore\n",
        "    for i in range(len(labels)):\n",
        "      if labels[i] in self.classes:\n",
        "        continue\n",
        "      else:\n",
        "        all_projections = np.asarray([y_all[int(ii)][i] for ii in self.classes])\n",
        "        all_w0 = np.asarray([self.training_values[int(ii)][1] for ii in self.classes])\n",
        "        distance = list((all_w0 - all_projections)/all_w0)\n",
        "        labels[i] = distance.index(min(distance))\n",
        "    return labels\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing our test and training data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "\n",
        "home_path = os.getcwd()\n",
        "path='./Train'\n",
        "os.chdir(path)\n",
        "Images=os.listdir()\n",
        "\n",
        "Images1=sorted(Images, key=lambda t: int(os.path.splitext(t)[0])) # sort them ascendingly\n",
        "ImagF=np.zeros((2400,784))  # All Images\n",
        "for i in range(len(Images1)):\n",
        "    ImagF1=imageio.imread(Images1[i])\n",
        "    ImagF[i,:]=ImagF1.reshape((1,784))\n",
        "\n\n",
        "os.chdir(home_path)\n",
        "lbls=np.loadtxt(\"Training Labels.txt\")\n",
        "lbls_T=np.loadtxt(\"Test Labels.txt\")\n",
        "path='./Test'\n",
        "os.chdir(path)\n",
        "Test_Image=os.listdir()\n",
        "Test_Image.pop()\n",
        "Test_Image1=sorted(Test_Image, key=lambda t: int(os.path.splitext(t)[0]))\n",
        "ImagF_T=np.zeros((200,784))\n",
        "for i in range(len(Test_Image1)):\n",
        "    Imag=imageio.imread(Test_Image1[i])\n",
        "    ImagF_T[i,:]=Imag.reshape((1,784))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The First run of our classifier:\n",
        "We will train our classifier and test its accuracy by doing a one to one comparison of each predicted label vs the true label"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = One_vs_all_fisher(ImagF, lbls)\n",
        "# Calculate Predicted labels\n",
        "t = classifier.classify(ImagF_T)\n",
        "\n",
        "#Calculate Accuracy and Print it\n",
        "Accuracy = 100*np.sum(t == lbls_T)/len(lbls_T)\n",
        "print(f\"Accuracy of predicted labels = {Accuracy}%\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving the accuracy by manipulating the data:\n",
        "A quick cursory look at the data will reveal that the numbers are not centered and that there's a varying amount of blank spaces arround the each number. we will work to make the numbers centered in the center of the image, and eliminate as much blank space as possible. \n",
        "\n",
        "Eliminating the blank space will reduce the number of features our program has to consider, improving speed and accuracy.\n",
        "\n",
        "## We are going to introduce two functions:\n",
        "- center, which crops all the blank space around the number, then pads the number to get the lowest dimension of the image to 28.\n",
        "- crop, which takes the resulting image from center and crops it down to the intended size"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def center(image):\n",
        "   mask = image>95\n",
        "   image = image[np.ix_(mask.any(1),mask.any(0))]\n",
        "   shortest_dimension = min(image.shape)\n",
        "   compensation = 14 - np.floor((shortest_dimension)//2)\n",
        "   return np.pad(image, pad_width = int(compensation), mode = 'constant', constant_values = 0)\n",
        "\n\n",
        "def crop(images,cropx,cropy):\n",
        "  no_of_images = images.shape[0]\n",
        "  images_cropped = np.empty((no_of_images , cropx * cropy) , dtype = int)\n",
        "\n",
        "  for i in range(no_of_images):\n",
        "    image = images[i,:].reshape(28,28)\n",
        "    image = center(image)\n",
        "    dimensions = image.shape\n",
        "    startx = (dimensions[1] - cropx)//2\n",
        "    starty = (dimensions[0]-cropy)//2\n",
        "    cropped_image = image[starty:(starty + cropy):,startx:(startx + cropx)].reshape(1, cropx * cropy)\n",
        "    images_cropped[i,:] = cropped_image\n",
        "    \n",
        "  return images_cropped"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing of the images:\n",
        "We are going to use center and crop to crop our images down to the size of 23 x 23 which after down many trails, I found that it produced the best accuracy scores."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "ImagF_crop = crop(ImagF,23,23)\n",
        "ImagF_T_crop = crop(ImagF_T,23,23)\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n\n\n",
        "for i in range(1,10,2):\n",
        "    axes = [plt.subplot(1, 4, i) for i in range(1,5)]\n",
        "    \n",
        "    axes[0].imshow(ImagF[-20+i*240,:].reshape(28,28))\n",
        "    axes[1].imshow(ImagF_crop[-20+i*240,:].reshape(23,23))\n",
        "    axes[2].imshow(ImagF[-20+(i+1)*240,:].reshape(28,28))\n",
        "    axes[3].imshow(ImagF_crop[-20+(i+1)*240,:].reshape(23,23))\n",
        "    \n",
        "    for i in range(0,4):\n",
        "        axes[i].set_title('Before Pre-Processing') if i//2 == 0 else axes[i].set_title('After Pre-Processing')\n",
        "        \n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runing our classifier on the pre-processed data:\n",
        "The accuracy improved from 74.5% to 79%!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = One_vs_all_fisher(ImagF_crop, lbls)\n",
        "t = classifier.classify(ImagF_T_crop)\n",
        "\n",
        "Accuracy = 100*np.sum(t == lbls_T)/len(lbls_T)\n",
        "print(f\"Accuracy of predicted labels = {Accuracy}% with image 23 x 23\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix and classification report:\n",
        "We will use scikit learn to produce the confusion matrix"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cm = confusion_matrix(lbls_T, t)\n",
        "\n",
        "print('Confusion Matrix: ')\n",
        "print(cm)\n",
        "print('\\n', 'Accuracy Score :',accuracy_score(lbls_T, t))\n",
        "print('\\n', 'Report : ')\n",
        "print(classification_report(lbls_T, t))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the confusion matrix and saving it to Accuracy.jpg"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#This code to draw the confusion matrix is largely taken from sklearn documentation with minor edits\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "title = 'Confusion Matrix'\n",
        "\n",
        "classes = np.unique(lbls_T).astype(int)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, plt.cm.Greens)\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       title=title,\n",
        "       ylabel='Target label',\n",
        "       xlabel='Predicted label')\n",
        "\n",
        "ax.margins(y = 5)\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), ha=\"right\")\n",
        "\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j]),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "fig.tight_layout()\n",
        "\n",
        "os.chdir(home_path)\n",
        "fig.savefig('Confusion Matrix.png')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 4
}